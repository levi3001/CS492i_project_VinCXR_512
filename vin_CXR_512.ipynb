{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "vin_CXR_512.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/levi3001/CS492i_project_VinCXR_512/blob/master/vin_CXR_512.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3UTgFLMykxI",
        "outputId": "76fb28b4-5429-430b-d169-8292640ddf75"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASv50U6neOCC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZFJG39fy69G"
      },
      "source": [
        "!unzip -uq gdrive/MyDrive/cs492i_project/Vin_CXR_512.zip -d Vin_CXR_512/\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPTLJa64TTX-"
      },
      "source": [
        "#!pip install torch==1.4.0\n",
        "#!pip install torchvision==0.5.0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_FAPdvrzDzt"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import json \n",
        "import cv2 \n",
        "import torch.nn as nn"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOvTg1jvzc9S"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uH6wQbVzHha"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF23jLc1zaq-",
        "outputId": "9c5aa41f-4cc4-4399-e65b-6d5c58157773"
      },
      "source": [
        "!git clone https://github.com/levi3001/Yet-Another-EfficientDet-Pytorch.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Yet-Another-EfficientDet-Pytorch'...\n",
            "remote: Enumerating objects: 844, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 844 (delta 45), reused 70 (delta 41), pack-reused 765\u001b[K\n",
            "Receiving objects: 100% (844/844), 121.22 MiB | 14.43 MiB/s, done.\n",
            "Resolving deltas: 100% (482/482), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8qhxtiD8Uvp"
      },
      "source": [
        "if not Path('Yet-Another-EfficientDet-Pytorch/datasets').exists():\n",
        "    os.mkdir('Yet-Another-EfficientDet-Pytorch/datasets')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76fIDdq2Rw-b"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj6Pdq_k0mXo"
      },
      "source": [
        "!cp -r Vin_CXR_512/Vin_CXR_512/ Yet-Another-EfficientDet-Pytorch/datasets/Vin_CXR_512/"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTPsxpjs2GsQ",
        "outputId": "16e82b8f-505a-46ca-9b8b-7386ca24664d"
      },
      "source": [
        "cd /content/Yet-Another-EfficientDet-Pytorch/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Yet-Another-EfficientDet-Pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8edLC4zS9V7",
        "outputId": "14b53611-3922-4bdb-97a2-26ad0de8fd9f"
      },
      "source": [
        "ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "backbone.py                  \u001b[0m\u001b[01;34mprojects\u001b[0m/\n",
            "\u001b[01;34mbenchmark\u001b[0m/                   readme.md\n",
            "coco_eval.py                 \u001b[01;34mres\u001b[0m/\n",
            "\u001b[01;34mdatasets\u001b[0m/                    resnet50_best.pth\n",
            "\u001b[01;34mefficientdet\u001b[0m/                \u001b[01;34mtest\u001b[0m/\n",
            "efficientdet_test.py         train.py\n",
            "efficientdet_test_videos.py  \u001b[01;34mtutorial\u001b[0m/\n",
            "\u001b[01;34mefficientnet\u001b[0m/                \u001b[01;34mutils\u001b[0m/\n",
            "efficientnet_b0_best.pth     vin_CXR_512_classifier.ipynb\n",
            "LICENSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmRSs9KZ3CoL"
      },
      "source": [
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lNeTTZgLnKQ"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQSzifiA1Nuk",
        "outputId": "6b27d5f2-0360-4fed-e6c3-ad42ed335c36"
      },
      "source": [
        "! mkdir weights\n",
        "! wget https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/releases/download/1.0/efficientdet-d0.pth -O weights/efficientdet-d0.pth"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-16 12:23:00--  https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/releases/download/1.0/efficientdet-d0.pth\n",
            "Resolving github.com (github.com)... 13.114.40.48\n",
            "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/253385242/9b9d2100-791d-11ea-80b2-d35899cf95fe?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211216%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211216T122300Z&X-Amz-Expires=300&X-Amz-Signature=30f66671ba82da89686226714154f3af72f4db673c2449985b89ec36c412f273&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=253385242&response-content-disposition=attachment%3B%20filename%3Defficientdet-d0.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-12-16 12:23:00--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/253385242/9b9d2100-791d-11ea-80b2-d35899cf95fe?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211216%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211216T122300Z&X-Amz-Expires=300&X-Amz-Signature=30f66671ba82da89686226714154f3af72f4db673c2449985b89ec36c412f273&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=253385242&response-content-disposition=attachment%3B%20filename%3Defficientdet-d0.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15862583 (15M) [application/octet-stream]\n",
            "Saving to: ‘weights/efficientdet-d0.pth’\n",
            "\n",
            "weights/efficientde 100%[===================>]  15.13M  11.5MB/s    in 1.3s    \n",
            "\n",
            "2021-12-16 12:23:02 (11.5 MB/s) - ‘weights/efficientdet-d0.pth’ saved [15862583/15862583]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ThrCOV_03Svf",
        "outputId": "cd803ba9-a379-45c3-c61c-edde7583cd2d"
      },
      "source": [
        "! pip install tensorboardX tensorboard pyyaml webcolors \n",
        "!pip install -U git+https://github.com/albumentations-team/albumentations"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 92 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Collecting webcolors\n",
            "  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.42.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n",
            "Installing collected packages: webcolors, tensorboardX\n",
            "Successfully installed tensorboardX-2.4.1 webcolors-1.11.1\n",
            "Collecting git+https://github.com/albumentations-team/albumentations\n",
            "  Cloning https://github.com/albumentations-team/albumentations to /tmp/pip-req-build-u2cs1nac\n",
            "  Running command git clone -q https://github.com/albumentations-team/albumentations /tmp/pip-req-build-u2cs1nac\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.1.0) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==1.1.0) (1.4.1)\n",
            "Requirement already satisfied: scikit-image<0.19,>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.1.0) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==1.1.0) (3.13)\n",
            "Collecting qudida>=0.0.4\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.1.0) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations==1.1.0) (1.0.1)\n",
            "Collecting opencv-python-headless>=4.0.1\n",
            "  Downloading opencv_python_headless-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.6 MB 170 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations==1.1.0) (3.10.0.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (1.2.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2021.11.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.1.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.1.0) (3.0.0)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-1.1.0-py3-none-any.whl size=105152 sha256=ca548f388702bcf715234d90b01d4b532ba34adefccc67571f0509fd4557d188\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sgdeuvwq/wheels/3a/25/ed/ec3b518e7a332d7f0a3bb37c280e1b784cf2f79b94b3c7d00b\n",
            "Successfully built albumentations\n",
            "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-1.1.0 opencv-python-headless-4.5.4.60 qudida-0.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgV-LmncTNqF"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do6kh-WW4uRp"
      },
      "source": [
        "import yaml\n",
        "config={\n",
        "        'project_name': 'Vin_CXR_512' , \n",
        "        'train_set': 'train',\n",
        "        'val_set': 'val',\n",
        "        'num_gpus': 1,\n",
        "        'num_workers': 1,\n",
        "        'mean': [ 0.485, 0.456, 0.406 ],\n",
        "        'std': [ 0.229, 0.224, 0.225 ],\n",
        "\n",
        "        'anchors_scales': '[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]',\n",
        "        'anchors_ratios': '[(1.0, 1.0), (1.3, 0.8), (1.9, 0.5)]',\n",
        "\n",
        "        'obj_list': [\"Aortic_enlargement\",\n",
        "            \"Atelectasis\",\n",
        "            \"Calcification\",\n",
        "            \"Cardiomegaly\",\n",
        "            \"Consolidation\",\n",
        "            \"ILD\",\n",
        "            \"Infiltration\",\n",
        "            \"Lung_Opacity\",\n",
        "            \"Nodule/Mass\",\n",
        "            \"Other_lesion\",\n",
        "            \"Pleural_effusion\",\n",
        "            \"Pleural_thickening\",\n",
        "            \"Pneumothorax\",\n",
        "            \"Pulmonary_fibrosis\"]\n",
        "    }\n",
        "file = open(\"projects/Vin_CXR_512.yml\", \"w\")\n",
        "yaml.dump(config, file)\n",
        "file.close()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9rSil3TZQdR"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNPVDS_V2LoR",
        "outputId": "724d030a-5f45-443d-c2a9-2b2cca1bc1ae"
      },
      "source": [
        "!python train.py -c 0 -cb 3 -p Vin_CXR_512 --batch_size 8 --lr 1e3 --num_epochs 50 --custom_backbone /content/gdrive/MyDrive/cs492i_project/efficientnet_b3_best.pth"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 347, in <module>\n",
            "    train(opt)\n",
            "  File \"train.py\", line 146, in train\n",
            "    ratios=eval(params.anchors_ratios), scales=eval(params.anchors_scales))\n",
            "  File \"/content/Yet-Another-EfficientDet-Pytorch/backbone.py\", line 60, in __init__\n",
            "    self.backbone_net = EfficientNet(self.backbone_compound_coef[compound_coef_backbone],num_classes, load_weights,custom_backbone)\n",
            "  File \"/content/Yet-Another-EfficientDet-Pytorch/efficientdet/model.py\", line 429, in __init__\n",
            "    model.load_state_dict(torch.load(custom_backbone))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1483, in load_state_dict\n",
            "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
            "RuntimeError: Error(s) in loading state_dict for EfficientNet:\n",
            "\tMissing key(s) in state_dict: \"_conv_stem.conv.weight\", \"_bn0.weight\", \"_bn0.bias\", \"_bn0.running_mean\", \"_bn0.running_var\", \"_blocks.0._depthwise_conv.conv.weight\", \"_blocks.0._bn1.weight\", \"_blocks.0._bn1.bias\", \"_blocks.0._bn1.running_mean\", \"_blocks.0._bn1.running_var\", \"_blocks.0._se_reduce.conv.weight\", \"_blocks.0._se_reduce.conv.bias\", \"_blocks.0._se_expand.conv.weight\", \"_blocks.0._se_expand.conv.bias\", \"_blocks.0._project_conv.conv.weight\", \"_blocks.0._bn2.weight\", \"_blocks.0._bn2.bias\", \"_blocks.0._bn2.running_mean\", \"_blocks.0._bn2.running_var\", \"_blocks.1._depthwise_conv.conv.weight\", \"_blocks.1._bn1.weight\", \"_blocks.1._bn1.bias\", \"_blocks.1._bn1.running_mean\", \"_blocks.1._bn1.running_var\", \"_blocks.1._se_reduce.conv.weight\", \"_blocks.1._se_reduce.conv.bias\", \"_blocks.1._se_expand.conv.weight\", \"_blocks.1._se_expand.conv.bias\", \"_blocks.1._project_conv.conv.weight\", \"_blocks.1._bn2.weight\", \"_blocks.1._bn2.bias\", \"_blocks.1._bn2.running_mean\", \"_blocks.1._bn2.running_var\", \"_blocks.2._expand_conv.conv.weight\", \"_blocks.2._bn0.weight\", \"_blocks.2._bn0.bias\", \"_blocks.2._bn0.running_mean\", \"_blocks.2._bn0.running_var\", \"_blocks.2._depthwise_conv.conv.weight\", \"_blocks.2._bn1.weight\", \"_blocks.2._bn1.bias\", \"_blocks.2._bn1.running_mean\", \"_blocks.2._bn1.running_var\", \"_blocks.2._se_reduce.conv.weight\", \"_blocks.2._se_reduce.conv.bias\", \"_blocks.2._se_expand.conv.weight\", \"_blocks.2._se_expand.conv.bias\", \"_blocks.2._project_conv.conv.weight\", \"_blocks.2._bn2.weight\", \"_blocks.2._bn2.bias\", \"_blocks.2._bn2.running_mean\", \"_blocks.2._bn2.running_var\", \"_blocks.3._expand_conv.conv.weight\", \"_blocks.3._bn0.weight\", \"_blocks.3._bn0.bias\", \"_blocks.3._bn0.running_mean\", \"_blocks.3._bn0.running_var\", \"_blocks.3._depthwise_conv.conv.weight\", \"_blocks.3._bn1.weight\", \"_blocks.3._bn1.bias\", \"_blocks.3._bn1.running_mean\", \"_blocks.3._bn1.running_var\", \"_blocks.3._se_reduce.conv.weight\", \"_blocks.3._se_reduce.conv.bias\", \"_blocks.3._se_expand.conv.weight\", \"_blocks.3._se_expand.conv.bias\", \"_blocks.3._project_conv.conv.weight\", \"_blocks.3._bn2.weight\", \"_blocks.3._bn2.bias\", \"_blocks.3._bn2.running_mean\", \"_blocks.3._bn2.running_var\", \"_blocks.4._expand_conv.conv.weight\", \"_blocks.4._bn0.weight\", \"_blocks.4._bn0.bias\", \"_blocks.4._bn0.running_mean\", \"_blocks.4._bn0.running_var\", \"_blocks.4._depthwise_conv.conv.weight\", \"_blocks.4._bn1.weight\", \"_blocks.4._bn1.bias\", \"_blocks.4._bn1.running_mean\", \"_blocks.4._bn1.running_var\", \"_blocks.4._se_reduce.conv.weight\", \"_blocks.4._se_reduce.conv.bias\", \"_blocks.4._se_expand.conv.weight\", \"_blocks.4._se_expand.conv.bias\", \"_blocks.4._project_conv.conv.weight\", \"_blocks.4._bn2.weight\", \"_blocks.4._bn2.bias\", \"_blocks.4._bn2.running_mean\", \"_blocks.4._bn2.running_var\", \"_blocks.5._expand_conv.conv.weight\", \"_blocks.5._bn0.weight\", \"_blocks.5._bn0.bias\", \"_blocks.5._bn0.running_mean\", \"_blocks.5._bn0.running_var\", \"_blocks.5._depthwise_conv.conv.weight\", \"_blocks.5._bn1.weight\", \"_blocks.5._bn1.bias\", \"_blocks.5._bn1.running_mean\", \"_blocks.5._bn1.running_var\", \"_blocks.5._se_reduce.conv.weight\", \"_blocks.5._se_reduce.conv.bias\", \"_blocks.5._se_expand.conv.weight\", \"_blocks.5._se_expand.conv.bias\", \"_blocks.5._project_conv.conv.weight\", \"_blocks.5._bn2.weight\", \"_blocks.5._bn2.bias\", \"_blocks.5._bn2.running_mean\", \"_blocks.5._bn2.running_var\", \"_blocks.6._expand_conv.conv.weight\", \"_blocks.6._bn0.weight\", \"_blocks.6._bn0.bias\", \"_blocks.6._bn0.running_mean\", \"_blocks.6._bn0.running_var\", \"_blocks.6._depthwise_conv.conv.weight\", \"_blocks.6._bn1.weight\", \"_blocks.6._bn1.bias\", \"_blocks.6._bn1.running_mean\", \"_blocks.6._bn1.running_var\", \"_blocks.6._se_reduce.conv.weight\", \"_blocks.6._se_reduce.conv.bias\", \"_blocks.6._se_expand.conv.weight\", \"_blocks.6._se_expand.conv.bias\", \"_blocks.6._project_conv.conv.weight\", \"_blocks.6._bn2.weight\", \"_blocks.6._bn2.bias\", \"_blocks.6._bn2.running_mean\", \"_blocks.6._bn2.running_var\", \"_blocks.7._expand_conv.conv.weight\", \"_blocks.7._bn0.weight\", \"_blocks.7._bn0.bias\", \"_blocks.7._bn0.running_mean\", \"_blocks.7._bn0.running_var\", \"_blocks.7._depthwise_conv.conv.weight\", \"_blocks.7._bn1.weight\", \"_blocks.7._bn1.bias\", \"_blocks.7._bn1.running_mean\", \"_blocks.7._bn1.running_var\", \"_blocks.7._se_reduce.conv.weight\", \"_blocks.7._se_reduce.conv.bias\", \"_blocks.7._se_expand.conv.weight\", \"_blocks.7._se_expand.conv.bias\", \"_blocks.7._project_conv.conv.weight\", \"_blocks.7._bn2.weight\", \"_blocks.7._bn2.bias\", \"_blocks.7._bn2.running_mean\", \"_blocks.7._bn2.running_var\", \"_blocks.8._expand_conv.conv.weight\", \"_blocks.8._bn0.weight\", \"_blocks.8._bn0.bias\", \"_blocks.8._bn0.running_mean\", \"_blocks.8._bn0.running_var\", \"_blocks.8._depthwise_conv.conv.weight\", \"_blocks.8._bn1.weight\", \"_blocks.8._bn1.bias\", \"_blocks.8._bn1.running_mean\", \"_blocks.8._bn1.running_var\", \"_blocks.8._se_reduce.conv.weight\", \"_blocks.8._se_reduce.conv.bias\", \"_blocks.8._se_expand.conv.weight\", \"_blocks.8._se_expand.conv.bias\", \"_blocks.8._project_conv.conv.weight\", \"_blocks.8._bn2.weight\", \"_blocks.8._bn2.bias\", \"_blocks.8._bn2.running_mean\", \"_blocks.8._bn2.running_var\", \"_blocks.9._expand_conv.conv.weight\", \"_blocks.9._bn0.weight\", \"_blocks.9._bn0.bias\", \"_blocks.9._bn0.running_mean\", \"_blocks.9._bn0.running_var\", \"_blocks.9._depthwise_conv.conv.weight\", \"_blocks.9._bn1.weight\", \"_blocks.9._bn1.bias\", \"_blocks.9._bn1.running_mean\", \"_blocks.9._bn1.running_var\", \"_blocks.9._se_reduce.conv.weight\", \"_blocks.9._se_reduce.conv.bias\", \"_blocks.9._se_expand.conv.weight\", \"_blocks.9._se_expand.conv.bias\", \"_blocks.9._project_conv.conv.weight\", \"_blocks.9._bn2.weight\", \"_blocks.9._bn2.bias\", \"_blocks.9._bn2.running_mean\", \"_blocks.9._bn2.running_var\", \"_blocks.10._expand_conv.conv.weight\", \"_blocks.10._bn0.weight\", \"_blocks.10._bn0.bias\", \"_blocks.10._bn0.running_mean\", \"_blocks.10._bn0.running_var\", \"_blocks.10._depthwise_conv.conv.weight\", \"_blocks.10._bn1.weight\", \"_blocks.10._bn1.bias\", \"_blocks.10._bn1.running_mean\", \"_blocks.10._bn1.running_var\", \"_blocks.10._se_reduce.conv.weight\", \"_blocks.10._se_reduce.conv.bias\", \"_blocks.10._se_expand.conv.weight\", \"_blocks.10._se_expand.conv.bias\", \"_blocks.10._project_conv.conv.weight\", \"_blocks.10._bn2.weight\", \"_blocks.10._bn2.bias\", \"_blocks.10._bn2.running_mean\", \"_blocks.10._bn2.running_var\", \"_blocks.11._expand_conv.conv.weight\", \"_blocks.11._bn0.weight\", \"_blocks.11._bn0.bias\", \"_blocks.11._bn0.running_mean\", \"_blocks.11._bn0.running_var\", \"_blocks.11._depthwise_conv.conv.weight\", \"_blocks.11._bn1.weight\", \"_blocks.11._bn1.bias\", \"_blocks.11._bn1.running_mean\", \"_blocks.11._bn1.running_var\", \"_blocks.11._se_reduce.conv.weight\", \"_blocks.11._se_reduce.conv.bias\", \"_blocks.11._se_expand.conv.weight\", \"_blocks.11._se_expand.conv.bias\", \"_blocks.11._project_conv.conv.weight\", \"_blocks.11._bn2.weight\", \"_blocks.11._bn2.bias\", \"_blocks.11._bn2.running_mean\", \"_blocks.11._bn2.running_var\", \"_blocks.12._expand_conv.conv.weight\", \"_blocks.12._bn0.weight\", \"_blocks.12._bn0.bias\", \"_blocks.12._bn0.running_mean\", \"_blocks.12._bn0.running_var\", \"_blocks.12._depthwise_conv.conv.weight\", \"_blocks.12._bn1.weight\", \"_blocks.12._bn1.bias\", \"_blocks.12._bn1.running_mean\", \"_blocks.12._bn1.running_var\", \"_blocks.12._se_reduce.conv.weight\", \"_blocks.12._se_reduce.conv.bias\", \"_blocks.12._se_expand.conv.weight\", \"_blocks.12._se_expand.conv.bias\", \"_blocks.12._project_conv.conv.weight\", \"_blocks.12._bn2.weight\", \"_blocks.12._bn2.bias\", \"_blocks.12._bn2.running_mean\", \"_blocks.12._bn2.running_var\", \"_blocks.13._expand_conv.conv.weight\", \"_blocks.13._bn0.weight\", \"_blocks.13._bn0.bias\", \"_blocks.13._bn0.running_mean\", \"_blocks.13._bn0.running_var\", \"_blocks.13._depthwise_conv.conv.weight\", \"_blocks.13._bn1.weight\", \"_blocks.13._bn1.bias\", \"_blocks.13._bn1.running_mean\", \"_blocks.13._bn1.running_var\", \"_blocks.13._se_reduce.conv.weight\", \"_blocks.13._se_reduce.conv.bias\", \"_blocks.13._se_expand.conv.weight\", \"_blocks.13._se_expand.conv.bias\", \"_blocks.13._project_conv.conv.weight\", \"_blocks.13._bn2.weight\", \"_blocks.13._bn2.bias\", \"_blocks.13._bn2.running_mean\", \"_blocks.13._bn2.running_var\", \"_blocks.14._expand_conv.conv.weight\", \"_blocks.14._bn0.weight\", \"_blocks.14._bn0.bias\", \"_blocks.14._bn0.running_mean\", \"_blocks.14._bn0.running_var\", \"_blocks.14._depthwise_conv.conv.weight\", \"_blocks.14._bn1.weight\", \"_blocks.14._bn1.bias\", \"_blocks.14._bn1.running_mean\", \"_blocks.14._bn1.running_var\", \"_blocks.14._se_reduce.conv.weight\", \"_blocks.14._se_reduce.conv.bias\", \"_blocks.14._se_expand.conv.weight\", \"_blocks.14._se_expand.conv.bias\", \"_blocks.14._project_conv.conv.weight\", \"_blocks.14._bn2.weight\", \"_blocks.14._bn2.bias\", \"_blocks.14._bn2.running_mean\", \"_blocks.14._bn2.running_var\", \"_blocks.15._expand_conv.conv.weight\", \"_blocks.15._bn0.weight\", \"_blocks.15._bn0.bias\", \"_blocks.15._bn0.running_mean\", \"_blocks.15._bn0.running_var\", \"_blocks.15._depthwise_conv.conv.weight\", \"_blocks.15._bn1.weight\", \"_blocks.15._bn1.bias\", \"_blocks.15._bn1.running_mean\", \"_blocks.15._bn1.running_var\", \"_blocks.15._se_reduce.conv.weight\", \"_blocks.15._se_reduce.conv.bias\", \"_blocks.15._se_expand.conv.weight\", \"_blocks.15._se_expand.conv.bias\", \"_blocks.15._project_conv.conv.weight\", \"_blocks.15._bn2.weight\", \"_blocks.15._bn2.bias\", \"_blocks.15._bn2.running_mean\", \"_blocks.15._bn2.running_var\", \"_blocks.16._expand_conv.conv.weight\", \"_blocks.16._bn0.weight\", \"_blocks.16._bn0.bias\", \"_blocks.16._bn0.running_mean\", \"_blocks.16._bn0.running_var\", \"_blocks.16._depthwise_conv.conv.weight\", \"_blocks.16._bn1.weight\", \"_blocks.16._bn1.bias\", \"_blocks.16._bn1.running_mean\", \"_blocks.16._bn1.running_var\", \"_blocks.16._se_reduce.conv.weight\", \"_blocks.16._se_reduce.conv.bias\", \"_blocks.16._se_expand.conv.weight\", \"_blocks.16._se_expand.conv.bias\", \"_blocks.16._project_conv.conv.weight\", \"_blocks.16._bn2.weight\", \"_blocks.16._bn2.bias\", \"_blocks.16._bn2.running_mean\", \"_blocks.16._bn2.running_var\", \"_blocks.17._expand_conv.conv.weight\", \"_blocks.17._bn0.weight\", \"_blocks.17._bn0.bias\", \"_blocks.17._bn0.running_mean\", \"_blocks.17._bn0.running_var\", \"_blocks.17._depthwise_conv.conv.weight\", \"_blocks.17._bn1.weight\", \"_blocks.17._bn1.bias\", \"_blocks.17._bn1.running_mean\", \"_blocks.17._bn1.running_var\", \"_blocks.17._se_reduce.conv.weight\", \"_blocks.17._se_reduce.conv.bias\", \"_blocks.17._se_expand.conv.weight\", \"_blocks.17._se_expand.conv.bias\", \"_blocks.17._project_conv.conv.weight\", \"_blocks.17._bn2.weight\", \"_blocks.17._bn2.bias\", \"_blocks.17._bn2.running_mean\", \"_blocks.17._bn2.running_var\", \"_blocks.18._expand_conv.conv.weight\", \"_blocks.18._bn0.weight\", \"_blocks.18._bn0.bias\", \"_blocks.18._bn0.running_mean\", \"_blocks.18._bn0.running_var\", \"_blocks.18._depthwise_conv.conv.weight\", \"_blocks.18._bn1.weight\", \"_blocks.18._bn1.bias\", \"_blocks.18._bn1.running_mean\", \"_blocks.18._bn1.running_var\", \"_blocks.18._se_reduce.conv.weight\", \"_blocks.18._se_reduce.conv.bias\", \"_blocks.18._se_expand.conv.weight\", \"_blocks.18._se_expand.conv.bias\", \"_blocks.18._project_conv.conv.weight\", \"_blocks.18._bn2.weight\", \"_blocks.18._bn2.bias\", \"_blocks.18._bn2.running_mean\", \"_blocks.18._bn2.running_var\", \"_blocks.19._expand_conv.conv.weight\", \"_blocks.19._bn0.weight\", \"_blocks.19._bn0.bias\", \"_blocks.19._bn0.running_mean\", \"_blocks.19._bn0.running_var\", \"_blocks.19._depthwise_conv.conv.weight\", \"_blocks.19._bn1.weight\", \"_blocks.19._bn1.bias\", \"_blocks.19._bn1.running_mean\", \"_blocks.19._bn1.running_var\", \"_blocks.19._se_reduce.conv.weight\", \"_blocks.19._se_reduce.conv.bias\", \"_blocks.19._se_expand.conv.weight\", \"_blocks.19._se_expand.conv.bias\", \"_blocks.19._project_conv.conv.weight\", \"_blocks.19._bn2.weight\", \"_blocks.19._bn2.bias\", \"_blocks.19._bn2.running_mean\", \"_blocks.19._bn2.running_var\", \"_blocks.20._expand_conv.conv.weight\", \"_blocks.20._bn0.weight\", \"_blocks.20._bn0.bias\", \"_blocks.20._bn0.running_mean\", \"_blocks.20._bn0.running_var\", \"_blocks.20._depthwise_conv.conv.weight\", \"_blocks.20._bn1.weight\", \"_blocks.20._bn1.bias\", \"_blocks.20._bn1.running_mean\", \"_blocks.20._bn1.running_var\", \"_blocks.20._se_reduce.conv.weight\", \"_blocks.20._se_reduce.conv.bias\", \"_blocks.20._se_expand.conv.weight\", \"_blocks.20._se_expand.conv.bias\", \"_blocks.20._project_conv.conv.weight\", \"_blocks.20._bn2.weight\", \"_blocks.20._bn2.bias\", \"_blocks.20._bn2.running_mean\", \"_blocks.20._bn2.running_var\", \"_blocks.21._expand_conv.conv.weight\", \"_blocks.21._bn0.weight\", \"_blocks.21._bn0.bias\", \"_blocks.21._bn0.running_mean\", \"_blocks.21._bn0.running_var\", \"_blocks.21._depthwise_conv.conv.weight\", \"_blocks.21._bn1.weight\", \"_blocks.21._bn1.bias\", \"_blocks.21._bn1.running_mean\", \"_blocks.21._bn1.running_var\", \"_blocks.21._se_reduce.conv.weight\", \"_blocks.21._se_reduce.conv.bias\", \"_blocks.21._se_expand.conv.weight\", \"_blocks.21._se_expand.conv.bias\", \"_blocks.21._project_conv.conv.weight\", \"_blocks.21._bn2.weight\", \"_blocks.21._bn2.bias\", \"_blocks.21._bn2.running_mean\", \"_blocks.21._bn2.running_var\", \"_blocks.22._expand_conv.conv.weight\", \"_blocks.22._bn0.weight\", \"_blocks.22._bn0.bias\", \"_blocks.22._bn0.running_mean\", \"_blocks.22._bn0.running_var\", \"_blocks.22._depthwise_conv.conv.weight\", \"_blocks.22._bn1.weight\", \"_blocks.22._bn1.bias\", \"_blocks.22._bn1.running_mean\", \"_blocks.22._bn1.running_var\", \"_blocks.22._se_reduce.conv.weight\", \"_blocks.22._se_reduce.conv.bias\", \"_blocks.22._se_expand.conv.weight\", \"_blocks.22._se_expand.conv.bias\", \"_blocks.22._project_conv.conv.weight\", \"_blocks.22._bn2.weight\", \"_blocks.22._bn2.bias\", \"_blocks.22._bn2.running_mean\", \"_blocks.22._bn2.running_var\", \"_blocks.23._expand_conv.conv.weight\", \"_blocks.23._bn0.weight\", \"_blocks.23._bn0.bias\", \"_blocks.23._bn0.running_mean\", \"_blocks.23._bn0.running_var\", \"_blocks.23._depthwise_conv.conv.weight\", \"_blocks.23._bn1.weight\", \"_blocks.23._bn1.bias\", \"_blocks.23._bn1.running_mean\", \"_blocks.23._bn1.running_var\", \"_blocks.23._se_reduce.conv.weight\", \"_blocks.23._se_reduce.conv.bias\", \"_blocks.23._se_expand.conv.weight\", \"_blocks.23._se_expand.conv.bias\", \"_blocks.23._project_conv.conv.weight\", \"_blocks.23._bn2.weight\", \"_blocks.23._bn2.bias\", \"_blocks.23._bn2.running_mean\", \"_blocks.23._bn2.running_var\", \"_blocks.24._expand_conv.conv.weight\", \"_blocks.24._bn0.weight\", \"_blocks.24._bn0.bias\", \"_blocks.24._bn0.running_mean\", \"_blocks.24._bn0.running_var\", \"_blocks.24._depthwise_conv.conv.weight\", \"_blocks.24._bn1.weight\", \"_blocks.24._bn1.bias\", \"_blocks.24._bn1.running_mean\", \"_blocks.24._bn1.running_var\", \"_blocks.24._se_reduce.conv.weight\", \"_blocks.24._se_reduce.conv.bias\", \"_blocks.24._se_expand.conv.weight\", \"_blocks.24._se_expand.conv.bias\", \"_blocks.24._project_conv.conv.weight\", \"_blocks.24._bn2.weight\", \"_blocks.24._bn2.bias\", \"_blocks.24._bn2.running_mean\", \"_blocks.24._bn2.running_var\", \"_blocks.25._expand_conv.conv.weight\", \"_blocks.25._bn0.weight\", \"_blocks.25._bn0.bias\", \"_blocks.25._bn0.running_mean\", \"_blocks.25._bn0.running_var\", \"_blocks.25._depthwise_conv.conv.weight\", \"_blocks.25._bn1.weight\", \"_blocks.25._bn1.bias\", \"_blocks.25._bn1.running_mean\", \"_blocks.25._bn1.running_var\", \"_blocks.25._se_reduce.conv.weight\", \"_blocks.25._se_reduce.conv.bias\", \"_blocks.25._se_expand.conv.weight\", \"_blocks.25._se_expand.conv.bias\", \"_blocks.25._project_conv.conv.weight\", \"_blocks.25._bn2.weight\", \"_blocks.25._bn2.bias\", \"_blocks.25._bn2.running_mean\", \"_blocks.25._bn2.running_var\", \"_conv_head.conv.weight\", \"_bn1.weight\", \"_bn1.bias\", \"_bn1.running_mean\", \"_bn1.running_var\", \"_fc.weight\", \"_fc.bias\". \n",
            "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.num_batches_tracked\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.num_batches_tracked\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.bn3.num_batches_tracked\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.0.downsample.1.num_batches_tracked\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.num_batches_tracked\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.num_batches_tracked\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.1.bn3.num_batches_tracked\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.bn1.num_batches_tracked\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.bn2.num_batches_tracked\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer1.2.bn3.num_batches_tracked\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.bn1.num_batches_tracked\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.bn2.num_batches_tracked\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.bn3.num_batches_tracked\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.0.downsample.1.num_batches_tracked\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.bn1.num_batches_tracked\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.bn2.num_batches_tracked\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.1.bn3.num_batches_tracked\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.bn1.num_batches_tracked\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.bn2.num_batches_tracked\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.2.bn3.num_batches_tracked\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.bn1.num_batches_tracked\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.bn2.num_batches_tracked\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer2.3.bn3.num_batches_tracked\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.num_batches_tracked\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.num_batches_tracked\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.bn3.num_batches_tracked\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.0.downsample.1.num_batches_tracked\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.num_batches_tracked\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.num_batches_tracked\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.1.bn3.num_batches_tracked\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.bn1.num_batches_tracked\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.bn2.num_batches_tracked\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.2.bn3.num_batches_tracked\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.bn1.num_batches_tracked\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.bn2.num_batches_tracked\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.3.bn3.num_batches_tracked\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.bn1.num_batches_tracked\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.bn2.num_batches_tracked\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.4.bn3.num_batches_tracked\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.bn1.num_batches_tracked\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.bn2.num_batches_tracked\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer3.5.bn3.num_batches_tracked\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.num_batches_tracked\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.num_batches_tracked\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.bn3.num_batches_tracked\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.0.downsample.1.num_batches_tracked\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.num_batches_tracked\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.num_batches_tracked\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.1.bn3.num_batches_tracked\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.bn1.num_batches_tracked\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.bn2.num_batches_tracked\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"layer4.2.bn3.num_batches_tracked\", \"fc.weight\", \"fc.bias\". \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px2Zjwgy_KEP",
        "outputId": "01082115-8c76-43da-8761-4a31e5f344e8"
      },
      "source": [
        "%cd /content/Yet-Another-EfficientDet-Pytorch/\n",
        "#get latest weight file\n",
        "%cd logs/Vin_CXR_512\n",
        "weight_file = !ls -Art | grep efficientdet\n",
        "%cd ../..\n",
        "\n",
        "#uncomment the next line to specify a weight file\n",
        "#weight_file[-1] = 'efficientdet-d0_49_1400.pth'\n",
        "\n",
        "! python coco_eval.py -c 0 -cb 3 -p Vin_CXR_512 -w '/content/Yet-Another-EfficientDet-Pytorch/logs/Vin_CXR_512/efficientdet-d0_70_31000.pth'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Yet-Another-EfficientDet-Pytorch\n",
            "/content/Yet-Another-EfficientDet-Pytorch/logs/Vin_CXR_512\n",
            "/content/Yet-Another-EfficientDet-Pytorch\n",
            "running coco-style evaluation on project Vin_CXR_512, weights /content/Yet-Another-EfficientDet-Pytorch/logs/Vin_CXR_512/efficientdet-d0_70_31000.pth...\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "100% 879/879 [01:18<00:00, 11.21it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.29s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=3.97s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.91s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.149\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y4y5Q6hSQfe",
        "outputId": "7d3a813c-26bc-4f9a-a5a9-364e6efa4899"
      },
      "source": [
        "!python train.py -c 0 -cb 3 -p Vin_CXR_512 --batch_size 8 --lr 1e-4 --num_epochs 100\\\n",
        " --load_weights  '/content/Yet-Another-EfficientDet-Pytorch/logs/Vin_CXR_512/efficientdet-d0_70_31000.pth'\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 347, in <module>\n",
            "    train(opt)\n",
            "  File \"train.py\", line 160, in train\n",
            "    ret = model.load_state_dict(torch.load(weights_path), strict=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/Yet-Another-EfficientDet-Pytorch/logs/Vin_CXR_512/efficientdet-d0_70_31000.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py -c 0 -cb 3 -p Vin_CXR_512 --batch_size 8 --lr 1e-4 --num_epochs 100\\\n",
        " --load_weights '/content/gdrive/MyDrive/cs492i_project/logs/efficientdet-d0_70_31000.pth'"
      ],
      "metadata": {
        "id": "AdvDbYJQYGJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9YW_tmP_FgU"
      },
      "source": [
        "import torch\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from backbone import EfficientDetBackbone\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
        "from utils.utils import preprocess, invert_affine, postprocess\n",
        "\n",
        "compound_coef = 0\n",
        "force_input_size = None  # set None to use default size\n",
        "val_path=Path('datasets/Vin_CXR_512/val')\n",
        "val_list= os.listdir(val_path)\n",
        "img_path = 'datasets/Vin_CXR_512/val/'+val_list[0]\n",
        "\n",
        "threshold = 0.1\n",
        "iou_threshold = 0.2\n",
        "\n",
        "use_cuda = True\n",
        "use_float16 = False\n",
        "cudnn.fastest = True\n",
        "cudnn.benchmark = True\n",
        "\n",
        "obj_list = [\"Aortic_enlargement\",\n",
        "            \"Atelectasis\",\n",
        "            \"Calcification\",\n",
        "            \"Cardiomegaly\",\n",
        "            \"Consolidation\",\n",
        "            \"ILD\",\n",
        "            \"Infiltration\",\n",
        "            \"Lung_Opacity\",\n",
        "            \"Nodule/Mass\",\n",
        "            \"Other_lesion\",\n",
        "            \"Pleural_effusion\",\n",
        "            \"Pleural_thickening\",\n",
        "            \"Pneumothorax\",\n",
        "            \"Pulmonary_fibrosis\"]\n",
        "\n",
        "# tf bilinear interpolation is different from any other's, just make do\n",
        "input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
        "input_size = input_sizes[compound_coef] if force_input_size is None else force_input_size\n",
        "ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=input_size)\n",
        "\n",
        "if use_cuda:\n",
        "    x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n",
        "else:\n",
        "    x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)\n",
        "\n",
        "x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)\n",
        "\n",
        "model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n",
        "\n",
        "                             # replace this part with your project's anchor config\n",
        "                             ratios=[(0.7, 1.4), (1.0, 1.0), (1.5, 0.7)],\n",
        "                             scales=[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\n",
        "try:\n",
        "    model.load_state_dict(torch.load('logs/Vin_CXR_512/'+weight_file[-1]))\n",
        "except:\n",
        "    pass\n",
        "model.requires_grad_(False)\n",
        "model.eval()\n",
        "\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "if use_float16:\n",
        "    model = model.half()\n",
        "\n",
        "with torch.no_grad():\n",
        "    features, regression, classification, anchors = model(x)\n",
        "\n",
        "    regressBoxes = BBoxTransform()\n",
        "    clipBoxes = ClipBoxes()\n",
        "\n",
        "    out = postprocess(x,\n",
        "                      anchors, regression, classification,\n",
        "                      regressBoxes, clipBoxes,\n",
        "                      threshold, iou_threshold)\n",
        "\n",
        "\n",
        "for i in range(len(ori_imgs)):\n",
        "    if len(out[i]['rois']) == 0:\n",
        "        continue\n",
        "    ori_imgs[i] = ori_imgs[i].copy()\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(ori_imgs[i])\n",
        "    \n",
        "    for j in range(len(out[i]['rois'])):\n",
        "        (x1, y1, x2, y2) = out[i]['rois'][j].astype(np.int)\n",
        "        cv2.rectangle(ori_imgs[i], (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
        "        obj = obj_list[out[i]['class_ids'][j]]\n",
        "        score = float(out[i]['scores'][j])\n",
        "\n",
        "        cv2.putText(ori_imgs[i], '{}, {:.3f}'.format(obj, score),\n",
        "                    (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                    (255, 255, 0), 1)\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.imshow(ori_imgs[i])\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvxmEPE5SOkO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTwK6RnJlg2w"
      },
      "source": [
        "!cp '/content/Yet-Another-EfficientDet-Pytorch/logs/Vin_CXR_512/efficientdet-d0_70_31000.pth'  /content/gdrive/MyDrive/cs492i_project/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6P899wewUi7"
      },
      "source": [
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o-MsLnL0auHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOkh22N6svip",
        "outputId": "dba137db-a708-4b3e-cd5b-cd664f224d76"
      },
      "source": [
        "params=config\n",
        "SET_NAME = params['val_set']\n",
        "VAL_GT = f'datasets/{params[\"project_name\"]}/annotations/instances_{SET_NAME}.json'\n",
        "VAL_IMGS = f'datasets/{params[\"project_name\"]}/{SET_NAME}/'\n",
        "MAX_IMAGES = 10000\n",
        "coco_gt = COCO(VAL_GT)\n",
        "image_ids = coco_gt.getImgIds()[:MAX_IMAGES]\n",
        "pred_json_path='/content/Yet-Another-EfficientDet-Pytorch/val_bbox_results.json'\n",
        "coco_pred = coco_gt.loadRes(pred_json_path)\n",
        "print('BBox')\n",
        "for i in range(14):\n",
        "    coco_eval = COCOeval(coco_gt, coco_pred, 'bbox')\n",
        "    coco_eval.params.imgIds = image_ids\n",
        "    coco_eval.params.catIds=[i]\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.26s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.017\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.061\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.022\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.067\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.39s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.901\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.549\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.514\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.637\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.644\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.156\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.229\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.017\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.038\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.086\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.152\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.152\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.043\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.023\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.018\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.079\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.126\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.129\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.064\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.197\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.041\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.144\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.256\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.056\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.151\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.076\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.10s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.045\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.29s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.15s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.032\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.172\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.419\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.31s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.31s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.054\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.161\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.144\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.237\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.62s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.11s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.124\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.143\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q31ChRHiswS6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}